\chapter{Il ragionamento induttivo}
\section{Il concetto di forza}
Nel ragionamento induttivi si \`e interessati alla probabilit\`a della conclusione date le premesse, ovvero alla probabilit\`a induttiva dell'argomentazione
che essendo dipendente dalla forza di premesse e conclusione rende necessario introdurre la nozione di forza di un'asserzione. La forza di un'asserzione
\`e direttamente proporzionale alla quantit\`a di informazioni che trasmette e pertanto un'asserzione forte risulta vera solamente in situazioni specifiche. 
Si pu\`o dare un'ulteriode definizione di forza come inversamente proporzionale alla sua probabilit\`a a priori ovvero la sua probabilit\`a a prescindere
da una qualunque evidenza. Le asserzioni pi\`u forti sono pertanto quelle cos\`i tanto da non poter essere vere in alcune circostanze, ovvero le asserzioni
logicamente impossibili. Le asserzioni pi\`u deboli sono invece quelle logicamente necessarie. Non sempre \`e possibile confrontare la forza di due 
assezioni, si possono tuttavia classificare insiemi di asserzioni rispetto alla loro forza relativa:
\begin{itemize}
\item Se $A$ implica deduttivamente $B$ ma $B$ non implica $A$ allora $A$ \`e pi\`u forte di $B$ in quanto le circostanze possibili di $A$ formano un
sottoinsieme di $B$.
\item se $A$ \`e logicamente equivalente \`e $B$ allora hanno la stessa forza in quanto le circostanze possibili di $A$ e $B$ formano lo stesso insie,. 
\end{itemize}
L'importanza della forza sta nel suo legame con la probabilit\`a induttiva che tende a variare in modo proporzionale alla forza delle premesse e 
inversamente alla forza della conclusione. 
\section{Il sillogismo statistico}
Si possono dividere le argomentazioni induttive in quelle che non presuppongono in alcun modo che l'universo sia uniforme o risponente a leggi generali e 
quelle che lo fanno. Le prime sono chiamate argomentazioni statistiche dato che le loro premesse sostengono la conclusione per ragioni statistiche o 
matematiche mentre le seconde sono denominate argomentazioni humeane. La stima della probabilit\`a induttiva per argomentazioni humeane dipende dal grado
della conclusione sulla certezza rispetto a leggi contingenti.
\subsection{Argomentazioni statistiche}
Un ovvio valore per la probabilit\`a induttiva per le argomentazioni statistiche \`e il valore percentuale si pu\`o determinare un sillogismo statistico
nella forma $\dfrac{n\text{ pertcentuale di }F\text{ \`e }G, x \text{ \`e } F}{x \text{ \`e } G}$, la sua probabilit\`a induttiva \`e $\frac{n}{100}$. 
\section{Generalizzazioni statistiche}
Nel caso di generalizzazioni statistiche ha come premesse statistiche di alcuni elementi di un insieme e una conclusione riguardo l'insieme nella sua 
interezza hanno forma: $\dfrac{n\text{ pertcentuale di }c \text{ elementi scelti a caso tra }F\text{ \`e }G}{n \text{ percento di tutti gli }F \text{ \`e } 
G}$. $c$ indica la grandezza del campione e se \`e abbastanza grande il sottoinsieme di $F$ con $c$ elementi \`e abbastanza rappesentativo. Il successo di 
questa argomentazione statistica dipende grandemente dalla casualit\`a della tecnica di campionamento in quanto altrimenti si genera una distorsione 
sistematica. La probabilit\`a induttiva della generalizzazione \`e proporzionale a $c$ e inversamente alla forza della conclusione. Si rende necessario 
accordare alla conclusione un margine di errore. 
\section{Generalizzazioni induttive e induzioni semplici}
Si chiama generalizzazione induttiva $\dfrac{n\text{ pertcento dei }c \text{ elementi di }F\text{finora osservati \`e }G}{n \text{ percento di tutti gli }F 
\text{ \`e }  G}$ non \`e una generalizzazione statistica in quanto $c$ non pu\`o essere casuale a causa di questo il ragionamento non pu\`o essere 
giustificato unicamente da ragionamenti matematici e presuppone l'uniformit\`a e sono generalizzazioni di tipo humeano. Questo tipo di generalizzazione \`e 
una forma di ragionamento debole in quanto il grado di uniformit\`a \`e incerto. Per aumentare la probabilit\`a induttiva si pu\`o indebolire una
conclusione riducendo la popolazione menzionata ad un solo individuo creando l'induzione semplice o per enumerazione:  $\dfrac{n\text{ pertcento dei }c 
\text{ elementi di }F\text{finora osservati \`e }G}{\text{Se si osserva un altro }F \text{ \`e }  G}$. A differenza dei sillogismi statistici le induzioni
semplici non diventano deduzioni quando $n=100$. 
\section{Induzione per analogia}
L'induzione per analogia \`e un tipo di argomentazione humeana: in un argomentazione per analogia si osserva che $x$ ha diverse propriet\`a $F_1,\dots,F_n$
con un altro oggetto $y$ e si osserva che $y$ gode anche di $G$, pertanto si reputa probabile che anche $x$ goda di $G$: $\dfrac{F_1x\land\dots\land F_nx, 
F_1y\land\dots\land F_ny, Gy}{Gx}$. Affermazioni di questa forma possono essere rafforzate rafforzando le premesse, indebolendo la conclusione o notando 
ulteriori propriet\`a in comune e aumentare la forza delle propriet\`a. \`E importante considerare la pertinenza di $G$ rispetto alle $F$. Si possono 
introdurre nuove analogie con altri oggetti per rafforzare la conclusione di un argomentazione ibrida.
\section{Inferenza causali e metodi di Mill}
Sia le argomentazioni statistiche che quelle humeane tentano di instaurare un nesso logico tra caratteristiche di un insieme e quelle di alcuni elementi
dell'insieme. Si considerino ora le inferenza causali in cui si tenta di identificare le cause di un evento o effetto. Queste procedure hanno due passi:
il primo consiste nella formulazione di una lista di cause sospette che nel secondo verranno eliminate per osservazione nel maggior numero possibile.
L'ipotesi che la causa reale \`e inclusa nella lista iniziale \`e generalmente induttiva mentre il secondo passo \`e deduttivo. Normalmente si giunge alla
lista di cause sospette attraverso un ragionamento prevalentemente analogico. Il processo di eliminazione dipende dal tipo di cause ricercate: 
\subsection{Causa necessaria o condizione causalmente necessaria}
Una causa necessaria per $E$ \`e una condizione in assenza della quale $E$ non si verifica mai ma essa si pu\`o verificare senza che accada $E$. Un effetto 
pu\`o avere diverse cause necessarie. Si riduce attraverso il metodo dell'accordo.
\subsubsection{Metodo dell'accordo}
Questo metodo \`e una procedura deduttiva. Per determinare quale nell'elenco di condizione sospette sia in effetti condizione necessaria si esaminano un
certo numero di casi diversi di $E$, ovvero di ricorrenze di effetti dello stesso tipo. Se in uno di questi casi una delle condizioni necessarie sospette 
non compare la si pu\`o eliminare. Si spera che la lista si riduca ad un solo elemento che comunque avr\`a un certo grado di incertezza in quanto 
si deve presupporre che l'elenco contenga la vera causa necessaria. 
\subsection{Causa sufficiente o condizione causalmente sufficiente}
Una causa sufficiente per $E$ \`e una condizione in presenza della quale $E$ si verifica sempre, anche se pu\`o manifestarsi senza che ci sia la causa. Un 
certo effetto pu\`o avere diverse cause sufficienti. Si riduce attraverso il metodo della differenza.
\subsubsection{Metodo della differenza}
Per determinare quali dele condizioni non sia una condizione sufficiente si considera quando una di esse ricorre senza $E$ e la si elimina. 
\subsection{Causa necessaria e sufficiente}
Si dice causa necessaria e sufficiente una causa che soddisfa i requisiti dei tipi precedenti. Si riduce attraverso il metodo del congiunto.
\subsubsection{Metodo del congiunto}
Nel metodo del congiunto si applicano simultaneamente i metodi dell'accordo e edella differenza e una causa potr\`e essere esclusa se si verifica senza $E$
o quando quest'ultimo si verifica senza di essa. 
\subsection{Dipendenza causale di una quantit\`a variabile da un'altra}
Una quantit\`a variabile $B$ si dice dipendente da una seconda quantit\`a variabile $A$ se un cambiamento in $A$ produce un cambiamento corrispondente in 
$B$. Si riduce attraverso il metodo della variazione concomitante.
\subsubsection{Metodo della variazione concomitante}
Questo metodo serve per ridurre un elenco di grandezze variabili che si ipotizza possano essere responsabili di un cambiamento specifico. Si scarta una
di esse se il suo valore rimane costante durante il cambiamento di $E$. 